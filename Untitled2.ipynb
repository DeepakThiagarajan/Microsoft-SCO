{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ee970b-14fc-4d9a-915a-4660fd226470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4758418 entries, 0 to 4758417\n",
      "Data columns (total 46 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Unnamed: 0          int64  \n",
      " 1   Id                  int64  \n",
      " 2   OrgId               int64  \n",
      " 3   IncidentId          int64  \n",
      " 4   AlertId             int64  \n",
      " 5   Timestamp           object \n",
      " 6   DetectorId          int64  \n",
      " 7   AlertTitle          int64  \n",
      " 8   Category            object \n",
      " 9   MitreTechniques     object \n",
      " 10  IncidentGrade       object \n",
      " 11  ActionGrouped       object \n",
      " 12  ActionGranular      object \n",
      " 13  EntityType          object \n",
      " 14  EvidenceRole        object \n",
      " 15  DeviceId            int64  \n",
      " 16  Sha256              int64  \n",
      " 17  IpAddress           int64  \n",
      " 18  Url                 int64  \n",
      " 19  AccountSid          int64  \n",
      " 20  AccountUpn          int64  \n",
      " 21  AccountObjectId     int64  \n",
      " 22  AccountName         int64  \n",
      " 23  DeviceName          int64  \n",
      " 24  NetworkMessageId    int64  \n",
      " 25  EmailClusterId      float64\n",
      " 26  RegistryKey         int64  \n",
      " 27  RegistryValueName   int64  \n",
      " 28  RegistryValueData   int64  \n",
      " 29  ApplicationId       int64  \n",
      " 30  ApplicationName     int64  \n",
      " 31  OAuthApplicationId  int64  \n",
      " 32  ThreatFamily        object \n",
      " 33  FileName            int64  \n",
      " 34  FolderPath          int64  \n",
      " 35  ResourceIdName      int64  \n",
      " 36  ResourceType        object \n",
      " 37  Roles               object \n",
      " 38  OSFamily            int64  \n",
      " 39  OSVersion           int64  \n",
      " 40  AntispamDirection   object \n",
      " 41  SuspicionLevel      object \n",
      " 42  LastVerdict         object \n",
      " 43  CountryCode         int64  \n",
      " 44  State               int64  \n",
      " 45  City                int64  \n",
      "dtypes: float64(1), int64(31), object(14)\n",
      "memory usage: 1.6+ GB\n",
      "\n",
      "First 5 Rows:\n",
      "   Unnamed: 0             Id  OrgId  IncidentId  AlertId  \\\n",
      "0     5172780  1709396985476     26       18583   687462   \n",
      "1     8470561   927712939180     33        5065     3990   \n",
      "2     5897583  1090921697002    201      150787   807590   \n",
      "3     3288552  1434519079555    204      108287    28575   \n",
      "4     4060961  1005022347708     54      528202  1458226   \n",
      "\n",
      "                  Timestamp  DetectorId  AlertTitle            Category  \\\n",
      "0  2024-06-06T05:56:47.000Z          31         813             Malware   \n",
      "1  2024-06-03T10:45:09.000Z          38          25              Impact   \n",
      "2  2024-06-13T03:36:40.000Z         419         444           Execution   \n",
      "3  2024-06-08T16:54:57.000Z          44        1233  SuspiciousActivity   \n",
      "4  2024-06-09T02:48:01.000Z         102       58829        Exfiltration   \n",
      "\n",
      "                                     MitreTechniques  ... ResourceType  \\\n",
      "0                                                NaN  ...          NaN   \n",
      "1                                                NaN  ...          NaN   \n",
      "2  T1047;T1059;T1053;T1569;T1059.001;T1053.002;T1...  ...          NaN   \n",
      "3                                                NaN  ...          NaN   \n",
      "4                                                NaN  ...          NaN   \n",
      "\n",
      "         Roles OSFamily OSVersion AntispamDirection  SuspicionLevel  \\\n",
      "0          NaN        5        66               NaN      Suspicious   \n",
      "1          NaN        5        66               NaN             NaN   \n",
      "2  Destination        5        66               NaN             NaN   \n",
      "3          NaN        5        66               NaN      Suspicious   \n",
      "4          NaN        5        66               NaN             NaN   \n",
      "\n",
      "   LastVerdict  CountryCode  State   City  \n",
      "0    Malicious          242   1445  10630  \n",
      "1          NaN          242   1445  10630  \n",
      "2          NaN          242   1445  10630  \n",
      "3   Suspicious          242   1445  10630  \n",
      "4          NaN          242   1445  10630  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "\n",
      "Dataset Shape:\n",
      "(4758418, 46)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (update the path if needed)\n",
    "train_file_path = r\"D:\\Capstone projects\\Microsoft SCO\\new_train_sample.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(train_file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Shape:\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0284ac0a-5d13-4eb0-a461-7cfd377e5e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info After Preprocessing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4758418 entries, 0 to 4758417\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Dtype\n",
      "---  ------              -----\n",
      " 0   DetectorId          int64\n",
      " 1   AlertTitle          int64\n",
      " 2   Category            int64\n",
      " 3   IncidentGrade       int64\n",
      " 4   EntityType          int64\n",
      " 5   EvidenceRole        int64\n",
      " 6   RegistryKey         int64\n",
      " 7   RegistryValueName   int64\n",
      " 8   RegistryValueData   int64\n",
      " 9   ApplicationId       int64\n",
      " 10  ApplicationName     int64\n",
      " 11  OAuthApplicationId  int64\n",
      " 12  FileName            int64\n",
      " 13  FolderPath          int64\n",
      " 14  ResourceIdName      int64\n",
      " 15  OSFamily            int64\n",
      " 16  OSVersion           int64\n",
      " 17  CountryCode         int64\n",
      " 18  State               int64\n",
      " 19  City                int64\n",
      " 20  hour                int32\n",
      " 21  day_of_week         int32\n",
      " 22  month               int32\n",
      "dtypes: int32(3), int64(20)\n",
      "memory usage: 780.5 MB\n",
      "\n",
      "First 5 Rows After Preprocessing:\n",
      "   DetectorId  AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  \\\n",
      "0          31         813        12              0           9             1   \n",
      "1          38          25         9              0          17             0   \n",
      "2         419         444         6              0          17             0   \n",
      "3          44        1233        16              2           9             1   \n",
      "4         102       58829         7              0           9             0   \n",
      "\n",
      "   RegistryKey  RegistryValueName  RegistryValueData  ApplicationId  ...  \\\n",
      "0         1631                635                860           2251  ...   \n",
      "1         1631                635                860           2251  ...   \n",
      "2         1631                635                860           2251  ...   \n",
      "3         1631                635                860           2251  ...   \n",
      "4         1631                635                860           2251  ...   \n",
      "\n",
      "   FolderPath  ResourceIdName  OSFamily  OSVersion  CountryCode  State   City  \\\n",
      "0        4227            3586         5         66          242   1445  10630   \n",
      "1      117668            3586         5         66          242   1445  10630   \n",
      "2      117668            3586         5         66          242   1445  10630   \n",
      "3        9177            3586         5         66          242   1445  10630   \n",
      "4      114449            3586         5         66          242   1445  10630   \n",
      "\n",
      "   hour  day_of_week  month  \n",
      "0     5            3      6  \n",
      "1    10            0      6  \n",
      "2     3            3      6  \n",
      "3    16            5      6  \n",
      "4     2            6      6  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dropping irrelevant columns\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', 'Id', 'IncidentId', 'AlertId', 'OrgId', 'DeviceId', \n",
    "    'Sha256', 'IpAddress', 'Url', 'AccountSid', 'AccountUpn', 'AccountObjectId', \n",
    "    'AccountName', 'DeviceName', 'NetworkMessageId'\n",
    "]\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "# Handling missing values - Drop columns with more than 50% missing values\n",
    "threshold = 0.5 * len(df)\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Convert 'Timestamp' to datetime and extract date-related features\n",
    "if 'Timestamp' in df.columns:\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    df['hour'] = df['Timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['Timestamp'].dt.dayofweek\n",
    "    df['month'] = df['Timestamp'].dt.month\n",
    "    df = df.drop(columns=['Timestamp'])\n",
    "\n",
    "# Encoding categorical features with label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoders = {}\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Check the processed data\n",
    "print(\"Data Info After Preprocessing:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nFirst 5 Rows After Preprocessing:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdef8a3-6fe3-4cad-8a36-9c5da0eb880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape (X_train, y_train): (3806734, 22) (3806734,)\n",
      "Testing Set Shape (X_test, y_test): (951684, 22) (951684,)\n",
      "\n",
      "Class Distribution in Training Set:\n",
      "IncidentGrade\n",
      "0    1643819\n",
      "2    1329669\n",
      "1     812626\n",
      "3      20620\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution in Testing Set:\n",
      "IncidentGrade\n",
      "0    410955\n",
      "2    332418\n",
      "1    203156\n",
      "3      5155\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['IncidentGrade'])\n",
    "y = df['IncidentGrade']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shapes of the resulting datasets\n",
    "print(\"Training Set Shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Set Shape (X_test, y_test):\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Check the class distribution in the training and testing sets\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution in Testing Set:\")\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd13815-90b3-40fe-9755-e56399584d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of Scaled Training Data:\n",
      "         DetectorId  AlertTitle  Category  EntityType  EvidenceRole  \\\n",
      "2091725   -0.254437   -0.257216  0.293729    1.394855     -1.099680   \n",
      "3579682   -0.242939   -0.254249  1.865140    1.394855     -1.099680   \n",
      "3434340   -0.238340   -0.256692  0.293729   -0.665117      0.909356   \n",
      "2399537   -0.222243   -0.256169 -1.801485   -1.513340      0.909356   \n",
      "2631676    0.120398   -0.245522  0.293729   -0.059242      0.909356   \n",
      "\n",
      "         RegistryKey  RegistryValueName  RegistryValueData  ApplicationId  \\\n",
      "2091725     0.042339           0.020889           0.023385       0.150983   \n",
      "3579682     0.042339           0.020889           0.023385       0.150983   \n",
      "3434340     0.042339           0.020889           0.023385       0.150983   \n",
      "2399537     0.042339           0.020889           0.023385       0.150983   \n",
      "2631676     0.042339           0.020889           0.023385       0.150983   \n",
      "\n",
      "         ApplicationName  ...  FolderPath  ResourceIdName  OSFamily  \\\n",
      "2091725          0.15318  ...    0.312063        0.028137  0.144266   \n",
      "3579682          0.15318  ...    0.312063        0.028137  0.144266   \n",
      "3434340          0.15318  ...    0.312063        0.028137  0.144266   \n",
      "2399537          0.15318  ...    0.312063        0.028137  0.144266   \n",
      "2631676          0.15318  ...    0.312063        0.028137  0.144266   \n",
      "\n",
      "         OSVersion  CountryCode     State      City      hour  day_of_week  \\\n",
      "2091725   0.144372     0.291784  0.266466  0.266194 -0.464857     1.880300   \n",
      "3579682   0.144372     0.291784  0.266466  0.266194 -0.907220     0.807735   \n",
      "3434340   0.144372    -3.562350 -3.824378 -3.804116 -0.022494    -0.801112   \n",
      "2399537   0.144372     0.291784  0.266466  0.266194  0.567324     0.271453   \n",
      "2631676   0.144372     0.291784  0.266466  0.266194  0.567324    -1.337394   \n",
      "\n",
      "            month  \n",
      "2091725  0.310683  \n",
      "3579682  0.310683  \n",
      "3434340  0.310683  \n",
      "2399537  0.310683  \n",
      "2631676  0.310683  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Mean of Scaled Training Data (should be close to 0):\n",
      "DetectorId           -3.744282e-18\n",
      "AlertTitle           -1.116192e-17\n",
      "Category             -1.503761e-16\n",
      "EntityType           -2.062715e-16\n",
      "EvidenceRole          8.272886e-17\n",
      "RegistryKey           1.024593e-15\n",
      "RegistryValueName     2.842646e-15\n",
      "RegistryValueData    -2.459605e-15\n",
      "ApplicationId        -1.932617e-16\n",
      "ApplicationName      -1.950312e-16\n",
      "OAuthApplicationId    3.993884e-15\n",
      "FileName              5.792252e-17\n",
      "FolderPath            2.100009e-16\n",
      "ResourceIdName       -1.931983e-15\n",
      "OSFamily              2.550713e-16\n",
      "OSVersion             6.074100e-17\n",
      "CountryCode           2.136630e-17\n",
      "State                 2.530685e-16\n",
      "City                 -8.702564e-17\n",
      "hour                  1.180364e-16\n",
      "day_of_week           8.976945e-17\n",
      "month                 1.315950e-15\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of Scaled Training Data (should be close to 1):\n",
      "DetectorId            1.0\n",
      "AlertTitle            1.0\n",
      "Category              1.0\n",
      "EntityType            1.0\n",
      "EvidenceRole          1.0\n",
      "RegistryKey           1.0\n",
      "RegistryValueName     1.0\n",
      "RegistryValueData     1.0\n",
      "ApplicationId         1.0\n",
      "ApplicationName       1.0\n",
      "OAuthApplicationId    1.0\n",
      "FileName              1.0\n",
      "FolderPath            1.0\n",
      "ResourceIdName        1.0\n",
      "OSFamily              1.0\n",
      "OSVersion             1.0\n",
      "CountryCode           1.0\n",
      "State                 1.0\n",
      "City                  1.0\n",
      "hour                  1.0\n",
      "day_of_week           1.0\n",
      "month                 1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "numerical_columns = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Check the first few rows of the scaled training data\n",
    "print(\"First 5 Rows of Scaled Training Data:\")\n",
    "print(X_train.head())\n",
    "\n",
    "# Verify the scaling by checking the mean and standard deviation\n",
    "print(\"\\nMean of Scaled Training Data (should be close to 0):\")\n",
    "print(X_train[numerical_columns].mean())\n",
    "\n",
    "print(\"\\nStandard Deviation of Scaled Training Data (should be close to 1):\")\n",
    "print(X_train[numerical_columns].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138816e4-42d6-4c8a-b8a4-7f6f6555d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance:\n",
      "Accuracy: 0.4143\n",
      "Macro F1 Score: 0.3370\n",
      "Precision: 0.3724\n",
      "Recall: 0.5212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Initialize the Logistic Regression model with class weight balancing\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87b7000-0bf3-4a0d-a783-2759e141d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# //Analysis\n",
    "# These results suggest that the model has room for improvement. The low accuracy and F1 score indicate that it’s not performing well in differentiating between the classes. This is expected for a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa0bd1-9b5c-4284-89ba-7f0fe0abe53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "macro_f1_xgb = f1_score(y_test, y_pred_xgb, average='macro')\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='macro')\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"XGBoost Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_xgb:.4f}\")\n",
    "print(f\"Precision: {precision_xgb:.4f}\")\n",
    "print(f\"Recall: {recall_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693e021-b105-489b-b140-fb04ac431c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Complex analysis where blocked The MemoryError during hyperparameter tuning is due to the large size of your dataset and the extensive computation required for cross-validation with RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e433a78-6eb4-4cb4-87bf-06914ed99d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Downsample the training data (20% of the original training set)\n",
    "X_train_sample, y_train_sample = resample(X_train, y_train, replace=False, n_samples=int(0.2 * len(X_train)), random_state=42)\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "\n",
    "# Set up HalvingRandomSearchCV\n",
    "halving_search = HalvingRandomSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    factor=2,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the HalvingRandomSearchCV\n",
    "halving_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_model = halving_search.best_estimator_\n",
    "best_params = halving_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the tuned model on the test data\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "macro_f1_best = f1_score(y_test, y_pred_best, average='macro')\n",
    "precision_best = precision_score(y_test, y_pred_best, average='macro')\n",
    "recall_best = recall_score(y_test, y_pred_best, average='macro')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"\\nTuned XGBoost Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_best:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1_best:.4f}\")\n",
    "print(f\"Precision: {precision_best:.4f}\")\n",
    "print(f\"Recall: {recall_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffb7c6-729d-4dab-9c22-2efbb248205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "///chat gpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46ec27-7531-4698-9459-8bffa34b2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257ef89-f5a9-4950-b171-439baca0a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred_best, average='macro')\n",
    "recall = recall_score(y_test, y_pred_best, average='macro')\n",
    "f1 = f1_score(y_test, y_pred_best, average='macro')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a614d1-b1b1-4df1-a7a4-5ac065291009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarize the output labels (this converts the labels to a one-vs-rest format)\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])  # Adjust classes according to your problem\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['blue', 'green', 'red']  # Use appropriate colors for your classes\n",
    "\n",
    "for i, color in zip(range(y_test_bin.shape[1]), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve (One-vs-Rest) for Multiclass Classification')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print AUC values for each class\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    print(f\"Class {i} AUC: {roc_auc[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de44383-9d3d-42d6-b41f-37edcf731646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GUIDE_test = pd.read_csv(r\"D:\\Capstone projects\\Microsoft SCO\\GUIDE_Test.csv\")\n",
    "\n",
    "print(GUIDE_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d3ec8-11dc-4b29-a5cf-3dec1a0e1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GUIDE_test.isnull().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dad281-5cfe-4fa5-9b73-314031173a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "GUIDE_test.drop(columns=['MitreTechniques', 'ActionGrouped', 'ActionGranular', \n",
    "                         'EmailClusterId', 'ThreatFamily', 'ResourceType', \n",
    "                         'Roles', 'AntispamDirection', 'SuspicionLevel', 'LastVerdict'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436bcca-e47d-4046-bb14-11c676cd2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GUIDE_test.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ad7a2-7131-4ca1-94a3-e5f23cdfee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = GUIDE_test.drop(columns=['IncidentGrade'])  # Drop the target column from the features\n",
    "y = GUIDE_test['IncidentGrade']  # The target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2cf9fc-f0df-4939-8d1f-12a4da82da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns in your dataset (excluding categorical and timestamp columns)\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Now you can apply scaling to the numerical columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling only to numerical columns\n",
    "X_train_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
    "\n",
    "# Transform the test set using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# If you want to keep the other columns (like timestamps), you can concatenate them back\n",
    "X_train_final = pd.DataFrame(X_train_scaled, columns=numerical_cols)\n",
    "X_test_final = pd.DataFrame(X_test_scaled, columns=numerical_cols)\n",
    "\n",
    "# Optionally, merge with the non-numeric columns (e.g., timestamps or categorical columns)\n",
    "X_train_final = pd.concat([X_train.drop(columns=numerical_cols).reset_index(drop=True), X_train_final], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop(columns=numerical_cols).reset_index(drop=True), X_test_final], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2fe88-7df2-4d1a-9e61-62c50b5dd886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the training labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform the test labels\n",
    "y_test_encoded = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7f56c-e73e-4151-855a-8eeaebcf70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "best_model.fit(X_train_scaled, y_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2385f-3fef-47ef-addc-e78838e03825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
